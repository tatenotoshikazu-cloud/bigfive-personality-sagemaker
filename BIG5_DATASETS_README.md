# Big Five Personality Datasets - Quick Start Guide

## TL;DR - æœ€ã‚‚é‡è¦ãªæƒ…å ±

### âœ… æ­£ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåï¼ˆå®Ÿéš›ã«ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ï¼‰

| ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå | ã‚µã‚¤ã‚º | ç”¨é€” |
|--------------|--------|------|
| **jingjietan/essays-big5** | 2,470 | å°è¦æ¨¡ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ»å­¦ç¿’ âœ¨ ãŠã™ã™ã‚ |
| **jingjietan/pandora-big5** | 3,006,566 | å¤§è¦æ¨¡DLãƒ»ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚° |
| **Fatima0923/Automated-Personality-Prediction** | 20,877 | ä¸­è¦æ¨¡ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ |

### âŒ å­˜åœ¨ã—ãªã„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆä½¿ç”¨ä¸å¯ï¼‰
- `DavidIRL/real-persona-chat` â† å­˜åœ¨ã—ã¾ã›ã‚“
- ãã®ä»–ã€æ¤œè¨¼ã•ã‚Œã¦ã„ãªã„åå‰

---

## ğŸš€ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆï¼ˆ30ç§’ã§å§‹ã‚ã‚‹ï¼‰

### æœ€å°ã‚³ãƒ¼ãƒ‰ä¾‹

```python
from datasets import load_dataset

# æœ€ã‚‚ä½¿ã„ã‚„ã™ã„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆæ¨å¥¨ï¼‰
dataset = load_dataset("jingjietan/essays-big5")

# ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª
print(dataset['train'][0])
# {'text': 'Well, right now I\'m finishing up my senior year...',
#  'O': 1, 'C': 0, 'E': 1, 'A': 1, 'N': 0, 'ptype': 'OEAC'}
```

### ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æ§‹é€ 

```python
# essays-big5
{
    'text': str,           # ã‚¨ãƒƒã‚»ã‚¤ãƒ†ã‚­ã‚¹ãƒˆ
    'O': int (0/1),       # Opennessï¼ˆé–‹æ”¾æ€§ï¼‰
    'C': int (0/1),       # Conscientiousnessï¼ˆèª å®Ÿæ€§ï¼‰
    'E': int (0/1),       # Extraversionï¼ˆå¤–å‘æ€§ï¼‰
    'A': int (0/1),       # Agreeablenessï¼ˆå”èª¿æ€§ï¼‰
    'N': int (0/1),       # Neuroticismï¼ˆç¥çµŒç—‡çš„å‚¾å‘ï¼‰
    'ptype': str          # æ€§æ ¼ã‚¿ã‚¤ãƒ—ï¼ˆä¾‹: "OEAC"ï¼‰
}

# pandora-big5
{
    'text': str,           # Redditã‚³ãƒ¡ãƒ³ãƒˆ
    'O': float (0-100),   # Opennessã‚¹ã‚³ã‚¢
    'C': float (0-100),   # Conscientiousnessã‚¹ã‚³ã‚¢
    'E': float (0-100),   # Extraversionã‚¹ã‚³ã‚¢
    'A': float (0-100),   # Agreeablenessã‚¹ã‚³ã‚¢
    'N': float (0-100),   # Neuroticismã‚¹ã‚³ã‚¢
    'ptype': int (0-31)   # æ€§æ ¼ã‚¿ã‚¤ãƒ—ID
}
```

---

## ğŸ“ ã“ã®ãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ•ã‚¡ã‚¤ãƒ«

1. **big5_datasets_guide.md** - å®Œå…¨ã‚¬ã‚¤ãƒ‰ï¼ˆè©³ç´°ãªèª¬æ˜ãƒ»ä½¿ç”¨ä¾‹ï¼‰
2. **load_big5_datasets.py** - ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
3. **compare_datasets.py** - ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ¯”è¼ƒã‚¹ã‚¯ãƒªãƒ—ãƒˆ
4. **BIG5_DATASETS_README.md** - ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆï¼‰

---

## ğŸ¯ ç”¨é€”åˆ¥ãŠã™ã™ã‚ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ

### 1. å­¦ç¿’ãƒ»å°è¦æ¨¡ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ
```python
# jingjietan/essays-big5 ã‚’ä½¿ç”¨
dataset = load_dataset("jingjietan/essays-big5")

# ãƒ¡ãƒªãƒƒãƒˆ:
# âœ“ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰é€Ÿåº¦: é«˜é€Ÿï¼ˆ< 10ç§’ï¼‰
# âœ“ ã‚µã‚¤ã‚º: å°ã•ã„ï¼ˆ~5 MBï¼‰
# âœ“ ãƒ©ãƒ™ãƒ«: ã‚·ãƒ³ãƒ—ãƒ«ãªãƒã‚¤ãƒŠãƒªï¼ˆ0/1ï¼‰
# âœ“ æ‰±ã„ã‚„ã™ã„ï¼ˆ2,470ã‚µãƒ³ãƒ—ãƒ«ï¼‰
```

### 2. å¤§è¦æ¨¡ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°
```python
# jingjietan/pandora-big5 ã‚’ä½¿ç”¨
dataset = load_dataset("jingjietan/pandora-big5")

# ãƒ¡ãƒªãƒƒãƒˆ:
# âœ“ å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ï¼ˆ3M+ã‚µãƒ³ãƒ—ãƒ«ï¼‰
# âœ“ é€£ç¶šå€¤ã‚¹ã‚³ã‚¢ï¼ˆ0-100ï¼‰
# âœ“ å¤šæ§˜ãªRedditã‚³ãƒ¡ãƒ³ãƒˆ

# æ³¨æ„:
# âš ï¸  ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«æ™‚é–“ãŒã‹ã‹ã‚‹ï¼ˆ2-5åˆ†ï¼‰
# âš ï¸  511 MBã®ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ãŒå¿…è¦
```

### 3. ä¸­è¦æ¨¡ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ
```python
# Fatima0923/Automated-Personality-Prediction ã‚’ä½¿ç”¨
dataset = load_dataset("Fatima0923/Automated-Personality-Prediction")

# ãƒ¡ãƒªãƒƒãƒˆ:
# âœ“ ã¡ã‚‡ã†ã©è‰¯ã„ã‚µã‚¤ã‚ºï¼ˆ20,877ã‚µãƒ³ãƒ—ãƒ«ï¼‰
# âœ“ Redditã‚³ãƒ¡ãƒ³ãƒˆ
# âœ“ é«˜é€Ÿãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆ< 10ç§’ï¼‰
```

---

## ğŸ’» å®Ÿè¡Œå¯èƒ½ãªã‚¹ã‚¯ãƒªãƒ—ãƒˆ

### ã‚¹ã‚¯ãƒªãƒ—ãƒˆ1: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿

```bash
# essays-big5ã‚’èª­ã¿è¾¼ã‚€
python load_big5_datasets.py --dataset essays

# pandora-big5ã®ã‚µãƒ³ãƒ—ãƒ«1000ä»¶ã‚’èª­ã¿è¾¼ã‚€
python load_big5_datasets.py --dataset pandora --sample 1000

# çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º
python load_big5_datasets.py --dataset essays --stats
```

### ã‚¹ã‚¯ãƒªãƒ—ãƒˆ2: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ¯”è¼ƒ

```bash
# å…¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ¯”è¼ƒ
python compare_datasets.py

# å‡ºåŠ›ä¾‹:
# â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
# â”‚ Short Name      â”‚ Total Size â”‚ Text Type    â”‚ Label Type  â”‚
# â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
# â”‚ essays-big5     â”‚ 2,470      â”‚ Essays       â”‚ Binary      â”‚
# â”‚ pandora-big5    â”‚ 3,006,566  â”‚ Reddit       â”‚ Float       â”‚
# â”‚ ...             â”‚ ...        â”‚ ...          â”‚ ...         â”‚
# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

### å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒª

```bash
pip install datasets transformers pandas numpy scikit-learn

# ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ¯”è¼ƒç”¨ï¼‰
pip install tabulate
```

---

## ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆè©³ç´°æ¯”è¼ƒ

| é …ç›® | essays-big5 | pandora-big5 | automated-personality |
|------|-------------|--------------|---------------------|
| **ã‚µã‚¤ã‚º** | 2,470 | 3,006,566 | 20,877 |
| **ãƒ†ã‚­ã‚¹ãƒˆã‚¿ã‚¤ãƒ—** | ã‚¨ãƒƒã‚»ã‚¤ | Redditã‚³ãƒ¡ãƒ³ãƒˆ | Redditã‚³ãƒ¡ãƒ³ãƒˆ |
| **ãƒ©ãƒ™ãƒ«å½¢å¼** | Binary (0/1) | Float (0-100) | Float (0-99) |
| **ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º** | ~5 MB | 511 MB | 6.02 MB |
| **ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ™‚é–“** | < 10ç§’ | 2-5åˆ† | < 10ç§’ |
| **ãƒ©ã‚¤ã‚»ãƒ³ã‚¹** | Apache 2.0 | Apache 2.0 | ä¸æ˜ |
| **æ¨å¥¨ç”¨é€”** | å­¦ç¿’ãƒ»å°è¦æ¨¡ | å¤§è¦æ¨¡DL | ä¸­è¦æ¨¡ |

---

## ğŸ“š ä½¿ç”¨ä¾‹

### ä¾‹1: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®èª­ã¿è¾¼ã¿ã¨ç¢ºèª

```python
from datasets import load_dataset

# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿
dataset = load_dataset("jingjietan/essays-big5")

# ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ã®ç¢ºèª
print(f"Train: {len(dataset['train'])} samples")
print(f"Validation: {len(dataset['validation'])} samples")
print(f"Test: {len(dataset['test'])} samples")

# ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª
sample = dataset['train'][0]
print(f"\nText: {sample['text'][:100]}...")
print(f"Openness: {sample['O']}")
print(f"Conscientiousness: {sample['C']}")
print(f"Extraversion: {sample['E']}")
print(f"Agreeableness: {sample['A']}")
print(f"Neuroticism: {sample['N']}")
```

### ä¾‹2: ç°¡å˜ãªæ€§æ ¼äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«

```python
from datasets import load_dataset
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
import numpy as np

# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿
dataset = load_dataset("jingjietan/essays-big5")

# ãƒ†ã‚­ã‚¹ãƒˆã¨ãƒ©ãƒ™ãƒ«ã®æº–å‚™
train_texts = dataset['train']['text']
test_texts = dataset['test']['text']

# ç‰¹å¾´é‡æŠ½å‡º
vectorizer = TfidfVectorizer(max_features=1000)
X_train = vectorizer.fit_transform(train_texts)
X_test = vectorizer.transform(test_texts)

# Opennessã®äºˆæ¸¬ï¼ˆä¾‹ï¼‰
y_train = dataset['train']['O']
y_test = dataset['test']['O']

# ãƒ¢ãƒ‡ãƒ«è¨“ç·´
model = RandomForestClassifier(n_estimators=100)
model.fit(X_train, y_train)

# äºˆæ¸¬ã¨è©•ä¾¡
predictions = model.predict(X_test)
accuracy = accuracy_score(y_test, predictions)
print(f"Openness prediction accuracy: {accuracy:.2%}")

# æ–°ã—ã„ãƒ†ã‚­ã‚¹ãƒˆã§äºˆæ¸¬
new_text = ["I love trying new things and exploring creative ideas."]
new_features = vectorizer.transform(new_text)
prediction = model.predict(new_features)[0]
print(f"Predicted Openness: {prediction} (1=High, 0=Low)")
```

### ä¾‹3: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®çµ±è¨ˆåˆ†æ

```python
from datasets import load_dataset
import pandas as pd

# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆèª­ã¿è¾¼ã¿
dataset = load_dataset("jingjietan/essays-big5")

# DataFrameã«å¤‰æ›
df = pd.DataFrame(dataset['train'])

# Big Fiveç‰¹æ€§ã®åˆ†å¸ƒ
traits = ['O', 'C', 'E', 'A', 'N']
trait_names = ['Openness', 'Conscientiousness', 'Extraversion', 'Agreeableness', 'Neuroticism']

print("Big Five Trait Distribution:")
for trait, name in zip(traits, trait_names):
    count = df[trait].sum()
    percentage = (count / len(df)) * 100
    print(f"{name}: {count}/{len(df)} ({percentage:.1f}%)")

# ãƒ†ã‚­ã‚¹ãƒˆé•·ã®çµ±è¨ˆ
df['text_length'] = df['text'].apply(len)
print(f"\nText Length Statistics:")
print(f"Mean: {df['text_length'].mean():.0f} characters")
print(f"Median: {df['text_length'].median():.0f} characters")
print(f"Min: {df['text_length'].min()} characters")
print(f"Max: {df['text_length'].max()} characters")
```

---

## ğŸš¨ ã‚ˆãã‚ã‚‹ã‚¨ãƒ©ãƒ¼ã¨è§£æ±ºç­–

### ã‚¨ãƒ©ãƒ¼1: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒè¦‹ã¤ã‹ã‚‰ãªã„

```python
# âŒ é–“é•ã„
dataset = load_dataset("DavidIRL/real-persona-chat")
# DatasetNotFoundError: Dataset 'DavidIRL/real-persona-chat' doesn't exist

# âœ… æ­£ã—ã„
dataset = load_dataset("jingjietan/essays-big5")
```

### ã‚¨ãƒ©ãƒ¼2: ãƒ¡ãƒ¢ãƒªä¸è¶³ï¼ˆpandora-big5ãŒå¤§ãã™ãã‚‹ï¼‰

```python
# âŒ å•é¡Œ: å…¨ãƒ‡ãƒ¼ã‚¿ã‚’ä¸€åº¦ã«èª­ã¿è¾¼ã‚‚ã†ã¨ã™ã‚‹ã¨ãƒ¡ãƒ¢ãƒªä¸è¶³

# âœ… è§£æ±ºç­–1: ä¸€éƒ¨ã®ã¿èª­ã¿è¾¼ã‚€
dataset = load_dataset("jingjietan/pandora-big5", split="train[:10000]")

# âœ… è§£æ±ºç­–2: ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰
dataset = load_dataset("jingjietan/pandora-big5", streaming=True)
for sample in dataset['train'].take(100):
    print(sample)
```

### ã‚¨ãƒ©ãƒ¼3: ãƒ©ãƒ™ãƒ«å½¢å¼ã®é•ã„

```python
# essays-big5: Binary (0/1)
# pandora-big5: Float (0-100)

# çµ±ä¸€ã™ã‚‹å ´åˆã®å¤‰æ›ä¾‹

# Binary â†’ Float (0-100)
float_score = binary_label * 100  # 0 â†’ 0, 1 â†’ 100

# Float â†’ Binaryï¼ˆé–¾å€¤50ï¼‰
binary_label = 1 if float_score >= 50 else 0
```

---

## ğŸ”— é–¢é€£ãƒªãƒ³ã‚¯

### ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãƒšãƒ¼ã‚¸
- [jingjietan/essays-big5](https://huggingface.co/datasets/jingjietan/essays-big5)
- [jingjietan/pandora-big5](https://huggingface.co/datasets/jingjietan/pandora-big5)
- [Fatima0923/Automated-Personality-Prediction](https://huggingface.co/datasets/Fatima0923/Automated-Personality-Prediction)
- [google/Synthetic-Persona-Chat](https://huggingface.co/datasets/google/Synthetic-Persona-Chat)

### é–¢é€£ãƒ¢ãƒ‡ãƒ«
- [Minej/bert-base-personality](https://huggingface.co/Minej/bert-base-personality) - Big Fiveäºˆæ¸¬ç”¨BERTãƒ¢ãƒ‡ãƒ«
- [vladinc/bigfive-regression-model](https://huggingface.co/vladinc/bigfive-regression-model) - å›å¸°ãƒ¢ãƒ‡ãƒ«

### ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³
- [Big Five Personality Traits Collection](https://huggingface.co/collections/DmitryRyumin/big-five-personality-traits-661fb545292ab3d12a5a4890)

### ç ”ç©¶è«–æ–‡
- [PANDORA Dataset Paper](https://arxiv.org/abs/2004.04460)
- [Big5-Chat Paper](https://arxiv.org/abs/2410.16491)

---

## ğŸ“ ã¾ã¨ã‚

### âœ… ç¢ºèªæ¸ˆã¿ãƒ»åˆ©ç”¨å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ

1. **jingjietan/essays-big5** - æœ€ã‚‚ä½¿ã„ã‚„ã™ã„ã€åˆå¿ƒè€…ã«ãŠã™ã™ã‚
2. **jingjietan/pandora-big5** - å¤§è¦æ¨¡ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå‘ã‘
3. **Fatima0923/Automated-Personality-Prediction** - ä¸­è¦æ¨¡ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå‘ã‘

### ğŸ¯ æ¨å¥¨ãƒ•ãƒ­ãƒ¼

1. **å­¦ç¿’æ®µéš**: `essays-big5`ã§å®Ÿé¨“ãƒ»ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ä½œæˆ
2. **é–‹ç™ºæ®µéš**: `automated-personality`ã§ä¸­è¦æ¨¡ãƒ†ã‚¹ãƒˆ
3. **æœ¬ç•ªæ®µéš**: `pandora-big5`ã§å¤§è¦æ¨¡è¨“ç·´

### ğŸ“‚ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

1. `big5_datasets_guide.md`ã‚’èª­ã‚“ã§è©³ç´°ã‚’ç†è§£
2. `load_big5_datasets.py`ã‚’å®Ÿè¡Œã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’è©¦ã™
3. `compare_datasets.py`ã§å„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ¯”è¼ƒ
4. è‡ªåˆ†ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã«æœ€é©ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’é¸æŠ

---

**ä½œæˆæ—¥**: 2025-10-24
**æœ€çµ‚æ›´æ–°**: 2025-10-24
